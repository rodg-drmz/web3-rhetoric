---
title: Working Paper 2
---

> **Source:**  
> _working paper 2_  
> © 2023–2024 Modern Language Association of America and Conference on College Composition and Communication  
>  
> Reproduced for educational, non-commercial use under fair use guidelines.  
> Original: [https://aiandwriting.hcommons.org](https://aiandwriting.hcommons.org)


Generative  AI  and  Po licy  Devel op ment:  
Guidance from the MLA-CCCC Task Force
M LA -CCCC  Joint  Task  Force  on  Writing and  AI
April 2024
© 2024 Modern Language Association of America and Conference on Co llege C omp osition and Communication


  
2
MLA-CCCC  Joint  Task  Force
 
on  Wri ting  and AI  Members
Ko˜ Adisa (Howard Communit y College, MD)
Antonio By rd (Universit y of Missouri, Kansas Cit y)
Le onardo  Fl ores  (Ap p alachian  St ate  University)
Dav id  Gre en  (How ard  Universit y)
Holly  Has sel  (Michigan  Te chnol o gical  Universit y);  co chair
Sarah  Z.  Johnson  (Madison  Colle ge,  WI)
Mat t hew Kirschenbaum  (Universit y  of  Mary land, Coll e ge  Park)
A.  Lo cket t  (indep enden t  scholar)
Elizabeth Mat hew s Losh (William and Mary); cochair
Anna Mills (College of Marin)


  
3
G enerative  AI  and  Po licy  Development :  
 
Guidance from the MLA-CCCC Task Force
Co ntents
In t roduc t ion
 
˚
I .  Adopt ing  Tiere d  Policy  Language
 
˛
Scenario  ˝
 
˛
Ins t itu t ional Level
 
˙
Pro gram  or  Dep art ment Level
 
˙
Indiv idual- Clas s  Level
 
˙
II . Principles and Proces s Considerat ions for Implement ing GAI Policies
 
ˆ
Scenario  ˇ
 
ˆ
Principle ˝: Policies mus t keep academic integrit y, learning ou tcomes,  
 
and  t he  teacher-s tu den t relat ionship  at  t heir  core.
 
ˆ
Principle ˇ: GAI policies should reduce harm (to s tudents, to academic  
 
integrit y, and to t he educat ional mis sion) while keeping educat ional  
 
devel op men t  at  t he  cen ter.  Policies should  sup p ort  t he  devel op men t  
 
of  crit ical  AI  literacy  rat her  t han resort  to  blanket  res t ric t ions  on acces s.
 
˘
Principle : Tools for detec t ion and au t horship veri˜cat ion in GAI use  
 
should be used with cau t ion and discernment or not at all.
 
Detec t ion Programs
 
Veri˜cat ion Tools
 
˝
Scenario  
 
˝˝
Reec t ions on Principles and Proces s Considerat ions
 
˝ˇ
III . Policies for Facult y Use of GAI
 
˝ˇ
Scenario  ˚
 
˝ˇ
Use  of  GAI  for Prep aring  Course  Material s
 
˝˚
IV. Considering GAI™s Impac t on Key Policy Areas
 
˝˛
Conc lusion
 
˝ˆ
Acknowle d gmen ts
 
˝ˆ
Work s Cited and Consulted
 
˝ˆ
Resources
 
ˇ˝


G enerative  AI  and  Po licy  Development :  
 
Guidance from the MLA-CCCC Task Force
Introductio n
In the 
MLA-CCCC Joint Task Force on Writing and AI Working Paper: Overview of the Issues, Statement  
of  Principles,  a nd  Recommendations
, our task force provided guidance on generative A I (GA I) tool s,  
particularly large language models (LLMs), which are rapidly proliferating, changing, and increasingly being  
used in a variety of settings. For instruc tors in the aliated ˜elds wit hin writing, language, and literature  
studies represented by the Modern Language Association and Conference on College Composition and  
Communication,  a  chartered  conference  of  the  National Council  of  Teachers  of English,  these  tools  raise 
a number of practical and existential questions: What do they mean for the research, writing, and reading  
goals we set for students™ research and writ ingŠand for our own scholarship? What constitutes ethical  
uses of these tools and what does not? How do they comp licate our understanding of core textual beliefs  
about authorship, originality, and intellectual property? In our ˜rst working paper, we aimed to help facilitate  
conversations about these questions at the local level by providing a big-picture look at the risks and  
bene˜ts of GA I and recommending princip les to guide educators™ approach to these tools.
Sound policy development is the focus of this second working paper. A well-drafted policy acts as a  
touchstone,  enabling  stakeholders  to  enact  practices  that  are  equitable  and  that  hold  those  who  are  aected  
by the policy accountable for their choices (of course, policies can also be weaponized, used to surveil and  
punish).  At educational institutions, policy gets created and implemented by people at various levelsŠ
across the institution, within programs and departments, and by individual instructorsŠand must therefore  
be exible enough to accommodate a range of needs. When establishing policies on GA I use in classrooms  
in particular, it is imperative to consider how any given policy will impact stu dents™ and teachers™ lived 
experiences with writing, reading, language, and digital technology. Policy that fails to recognize that GA I  
tools are constantly evolving and that therefore misunderstand that their inuence on learning and teaching  
will shift may have unintended consequences that undermine t he goals of education: critical inquiry and  
problem-solving through knowledge making and composed knowledge.
Professional  organizations  like  those  we  represent  don™t  set  campus  policy,  of  course,  but  oer  guidance  
on it. Here, that is what we aim to do, using example scenarios to help inform policymakers about the  
most important considerations for setting policies for GA I in instructional settings in our ˜elds. In section I,  
we discuss strategies for developing shared app roaches to GA I among the inst itutional, department, and  
individual-class levels. In section II , we lay out principles and processes for implementing policy. In sectionIII ,  
we oer faculty-speci˜c guidance for using GA I. In section IV, we identify important quest ions to consider  
when developing policy in six key areas where GA I policies will aect writing, language, and literature  
instruction. Althou gh GA I presents thorny questions and no single approach will be right for everyone,  
we hope this working paper encourages thoughtful, nuanced policy decisions that invigorate trust in the  
academic integrity of students.
© Modern Language Association of America and Conference on Co llege Composition and Comunication


  
5
I.  Adopting  Tiered  Policy  Language
Scenario  1
In a meeting of a campus-speci˜c group working on AI practices and policies, it becomes clear that  
the dean from a powerful unit on campus is providing a signi˜cantly di˚erent (and more permissive)  
direction to a group of students than other uni ts on campus. The dean informs t he larger group that  
students using GAI tools for all the stages of the writing and research process is ﬁno di˚erent than  
visiting the writing center and working with a tutor.ﬂ What are some ways forward in this situation?
GA I will impact all ˜elds in which we teach and research, so it is important that A I policy in educational  
contexts is adaptable to various disciplinary frameworks and applications. There™s an evolving discussion  
in academic integrity studies around the limits and reach of ins titu tion-wide A I policy (M cDermott; Razi  
and Raz). Many academic integrity scholars are realizing that generative A I policies must have a tiered  
structureŠfor t he classroom, the program, and the institution. This will allow exibility as faculty members  
foster acquiring A I literacy skill s while protecting assessment practices that require a ﬁno A I ﬂ policy. The  
diculty in implementing such a nuanced policy approach will be, of course, a lack of clarity for students,  
faculty members, and members of the support sta like tutors. In addit ion, multiple policies on GA I across  
the various levels of an institution may conict with one another, leaving students unsure of what critical A I  
literacy practices are essential for critical inquiry and problem-solving . Policies may restrict some groups of  
students over others or limit who can access GA I on university or school district devices. This inconsistency  
may perpetuate educational strati˜cation, where some populations are better equipped to ethically and  
strategically use GA I over others. Policies, then, not only shape academic integrity p ractices but also grant  
power and privilege according to students™ and teachers™ positionality (Jones et al.).
We encourage readers to recall the purpose and goal of higher education and align policies with those  
reasons. In other words, design policies on GAI use that support higher educat ion as a liminal space for  
discovery, play,  and  experimentation.  Liminal  spaces  are  where  students encounter  ideas  that  challenge  their  
assumptions, prior knowledge, and perspectives and transform their thinking . Students attend colleges and  
universities not just for skill acquisition bu t to enter learning environments that invite them to perceive and  
engage with t he world dierently. Participating in critical inquiry and problem-solv ing leads to these profound  
learning revelations. GA I , similar to other technologies, may have some role to play in assisting learning, so it  
is important not to approach these issues with a presumption that restriction is always the best course.
Because of this, we recommend that A I policy be negotiated, decided, and enacted within the t hree  
separate but cross-inuential domains of an institut ion mentioned earlier: ins titutional, program and  
department, and individual instructor. When we use the term 
tiered  policy  langua ge
 it is not to imply  
hierarchy of one policy over another but to indicate that each domain of negotiated guidance must remain  
aligned (noncontradictory). The simplest way to achieve this is for policy language to become progressively  
broader as the group covered by the policy grows larger and more diverse in its aims and contexts.
Across all these domains, we recommend that decision-making processes should be inclusive of all 
groups that are aected by GA I policies (including, for example, ˜rst-generation students, marginalized  


  
6
or historically excluded groups, disabled students, graduate teaching assistants, non-tenure-track faculty  
members or lecturers). For example, disabled students and English-language learners may ˜nd reading  
and comprehending easier with the assistance of arti˜cial intelligence summarizing texts. Policy needs to  
be informed by conversations with faculty members and students who can speak to these issues from their 
lived experience. Their input will ensure that inequity is not encoded into policy.
Institutional Level
At this level, institutions provide the broadest A I policy with de˜nitions and guiding principles. The standards  
of conduct should integrate language about GA I use into existing academic integrity policy, placing A I under  
that umbrella of enforcement and implementation. However, this app roach should respect academic freedom  
and faculty governance. Academic or classroom-focused issues should be under t he purview of faculty 
governance  groups  like  faculty  senates.
Program  or  Depart ment  Level
To provide individual faculty members with the context and guidance they need, program or department  
leaders are encouraged to craft advisory documents around A I , giving direction to faculty members, which  
might inclu de scenarios, sample syllabus language, and narrowed principles of ethical use based on the  
speci˜c s of the discipline. To craft this guidance, program or department leaders may examine emerging  
scholarship about how AI is being used in their ˜eld, solicit feedback from students and faculty colleagues, 
and seek out recommendations from professional organizations, such as are found in this working paper.  
We recommend these program or department guidelines be reviewed regularly and revised if necessary,  
especially in response to how companies continue to evolve GAI ™s capabilities.
Indi vidual -Clas s  Level
The individual-class level is where enforceable policy needs to be clearest and most detailed for both  
students and faculty members. Teachers should craft GA I policy tailored to t he assignments on their syllabi  
that aligns wit h their institutional and depart ment guidelines but may include detailed instructions about  
limits,  uses,  and  purposes  of  A I.  Policies  are  not  necessarily  duplicated  but  must  be  responsive  to  the  
following areas of faculty autonomy:
Ł
 
Class Typ es.
 For example, a biology lab, a computer programming course, a literature or writing  
course,  a  historical  research  course,  graphic  design  and  multimodal  courses,  or  distinct  types  of  
courses  even  within  the  sam e departm ent  or  program  may  necessitate dierent  approaches.
Ł
 
Classroom or Instructor.
 For example, an introduction to literature class or ˜rst-year writing with  
multiple sections taught by contingent faculty members or graduate teaching assistants should  
be mindful of t heir labor when authorizing GA I. Faculty members who allow the use of GA I should  
clearly s tate the parameters on acceptable use (e.g ., ﬁGenerative A I may be used under the following  
conditions . . . ﬂ).


  
7
Ł
 
Assignment-Sp eci˜c  Policies.
 An instructor might make it acceptable to use GA I tools for some  
assignments (or parts of some assignments) and not others. For example, an instructor may add  
badges or icons to assignments that indicate dierent permissions of A I use.
Over the next year, colleges and universities are encouraged to craft broad GA I policies that emphasize  
context-speci˜c parameters, transparency, reection, and ethical acknowledgment. We emphasize that the  
levels described above should be in collaboration with each other to complement policies.
I I.  Principles  and  Process  Considerations  for  Implementing  GAI  Policies
Scenario  2
You are a leader in shared governance at your institution. Your campus executive leadership at what  
is  a  technology-focused  institution  is  ﬁfull  steam  ahead !ﬂ  on  A I toolsŠfor  research,  writing,  coding,  
and nearly every aspect of possible use. At the same time, you know from your governance work  
that faculty members, students, and sta˚ members are all at very di˚erent levels of knowledge,  
competence, and disposition around adopting AI to ols. What are the right steps to move the  
conversation  forward?
There is no question that addressing responsible and ethical use of GA I in academic spaces requires  
both a granular attention to areas of our work and also general principles that can guide us in those 
situational decisions. I n this section, we outline t hree essential principles that can serve as torchlights to  
assist  institutional-level,  program- or  departm ent-l evel,  and  individual-class-level  approaches  to  GA I.  These  
principles  are  not  m eant  to  sup plant  existing  policies  and  procedures;  nevertheless,  they  can  be  additives  to  
these  policies.
Principle  1:  Policies  must  keep  academic  in tegrity,  learning outcomes,  and  t he  teacher-studen t  
relat ionship  at  t heir  core.
A GA I policy based on learning outcomes focuses on the outcomes sought by speci˜c writing assignments 
and whether the use of A I supports or subverts these outcomes. Thus, goals and outcomes should be  
expressed clearly in the course syllabus, writing projects and assignment prompts, and rubric s used to  
assess either t he stages of the project or process or the ˜nal produc t. When composing writing projects and  
assignment prompts, instructors should reect on the pedagogical goals for each assignment and whether  
the goals warrant or prohibit the use of GA I in the various stages of the assignment. Instructors should  
therefore consider how students will disclose their use of GA I within the stages. Additionally, instructors  
should consider allowing the use of A I in areas that are not part of the learning outcomes for the as signment.
In this principle, we encourage teachers to think carefully about what the underpinning learning goals are  
for the assignment, which aspects of the assignment can be completed eectively by a GA I tool, and how  
or where in the process students might be given the option to use the tool. At the foundation, learning tasks  
should align the learning goals with the activity. For example, an instructor who wants students to use free-
writing (independently) for practicing invention should align the learning goal (for students to build their  


  
8
cognitive, metacognitive, and imaginat ive tools as writers) with t he GA I expectation (s tu dents should not  
use GA I for this task). In contrast, an instructor might want students to practice using all possible tools for  
organizing their existing content into a coherent text and might suggest a variety of resources, depending on  
the students™ comfort level (writing center tutor, a GA I tool, peer conversation, instructor conference) to help  
them  organize  their  thinking .
Principle 2: GAI policies should reduce harm (to student s, to academic integrity, and to t he 
educat ional  mis sion) while  keeping  educat ional  development  at  t he  center.  Policies  should  support  
t he development of crit ical AI literacy rat her t han resort to blanket rest rict ions on access.
The use of GA I can be governed by existing academic integrity policies, but the advancement of GA I  
capacity over current online resources means that they do not map directly onto existing policy. For example,  
using a GA I tool to help organize content, to learn about possible counterarguments to a position they are  
advocating in a persuasive paper, or to help format a citation works dierently in GA I than in a simple Google  
search. In t his way, we encourage instructors and policymakers to focus on policies that advance learning  
and that do not inict harm on students (e.g ., with harsh failure policies or permanent impacts on their  
academic record) or that impede s tudents™ ability to develop critical A I literacy (e.g ., a complete ban on GA I  
tools).
The primary goal of academic- integrity-based policies is to determine whether the use of A I is allowable  
or violates institutional academic integrity policies. The recommendations found throughout this working  
paper align with the guidelines from the International Center for Academic Integrity, but, ˜rst and foremost,  
instructors should be familiar with their own institutions™ policies to ensure students are being treated fairly.
We note t he extreme diculty of proof given the unreliability of GA I detection software and the various  
workarounds that are possible for a person determined to use GA I without acknowledging it. Here it should  
be helpful to turn to the institution™s exis ting ways of handling academic integrity situations where violations  
cannot  be  p roven  ab solutely.  We urge  reection  on  why  the  proof  is  necessary  and  whether  there  are  other,  
nonpunitive app roaches that support learning and academic integrity but do not require proof, such as the  
suggestions outlined later in this paper for meeting with the stu dent.
Additionally, faculty members must cult ivate their pedagogical principles and professional expertise instead  
of deferring to technological assessments that may be awed. Although faculty members should not be  
expected to always be able to distinguish AI text from student writing, their expertise and pedagogical  
practices should be valued components of their approach to academic integrity. Faculty members™  
concerns about their students™ reading, writ ing, and thinking skills should always be central to discussions  
of accountability and academic integrity.  In large survey courses when TAs are needed to evaluate student  
writing, TAs should be empowered to communicate their concerns to students and lead faculty members if  
there is suspected GA I use.
Finally, faculty members must cult ivate their own knowledge and expertise in GA I tools. Refusing to engage  
with GA I helps neither students nor the academic enterprise, as research, writing, reading, and other  
companion thinking tools are developing at a whirlwind rate and being integrated into students™ future  


  
9
workplaces from tech ˜rms to KŒ12 education to government oces. We simply cannot aord to adopt a  
stance of complete hostility to GA I: such a stance incurs the risk of GA I tools being integrated into the fabric  
of intellectual life without the bene˜t of humanistic and rhetorical expertise. Consider, for example, that  
blocking  pa rticula r we b sites  like
 ChatGPT
 through technology restrictions is looking less and less viable at  
the college or university level.
Likewise, faculty  m embers  must examine  their  own  implicit  biases  and assumptions  about  the  relationship  
between language and identity, taking care to avoid making negat ive assumptions about marginalized 
writers on t he basis of academic writing . Literature across a number of disciplines has shown that  
international s tu dents and multilingual students who are writing in English are more likely to be accused  
of GA I-related academic misconduct (Tzanni; Foltýnek et al.; Weber-Wul et al.). The problem is twofold.  
Studies have shown that GA I detectors are more likely to ag English prose written by nonnative speakers  
(Liang et al; Weber-Wul et al.), but even faculty members who do not use A I detectors should be aware that  
suspicions of misuse of GAI are often due to complex factors, including culture, context, and unconscious  
ﬁnative-speakerismﬂ  rather than  actual  misconduct  (Tzanni).
This eort poses signi˜cant challenges, however. Program directors and instructors may not have the  
resources or funding for such professional development. U nits and university administration should invest in  
professional development for instructors and oer stipends for their time and labor. In addition to planning  
trainings, however, they may want to support more immediate collaborative grassroots professional  
development eorts. For example, institutions could fund instructor communities of practice that meet each  
month to share resources and experiences with GA I in their classrooms and read scholarship on GA I in their  
discipline. Although GA I evolves quickly, we suggest holding to principles of small teaching (Lang; Darby and  
Lang). Do a few t hings well rather than several things poorly.
Principle 3: Tools for detect ion and aut hor ship veri˜cat ion in GAI use should be used wit h caut ion 
and  discernmen t  or  not  at  all.
In a variety of institutional settings, some educators and decision-makers are turning to accountability tools  
that claim to p rovide either veri˜cation of a writer™s process of composition or detection of percentages of  
GA I usage wit hin a text.
DE TEC TION PROGRA MS
Because detection soft ware is inherently awed and can be easily fooled (Thompson and Hsu), colleges  
and universities must be mindful of the power that instructors and adminis trators relinquish when detection  
software is used uncritically to evaluate GA I within student writing . The fallibility of detect ion software, like  
Turnitin
, creates a number of opportunities for v ulnerable student identities to be pro˜ led and accused  
without serious consideration of process, source evaluation and synthesis, or development of student  
reading and attribu tion practices (Coley; ﬁHowﬂ).
Even systems that are tested and trusted for accuracy can be evaded through software designed to mediate  
the detection of A I language and phrasing . Many students are already aware of how to run A I content 
through paraphrase or translation software. Additionally, many second language and multilingual students  


  
10
already use such translation software to aid their adaptation to academic forms of writing . They may be  
agged for using online translation tools that are essential to their acquisition of academic writing literacies.
College  and  university  administ rators  should  be  aware  of  and  should  make  faculty  members  aware  of  
the limitations of these detection tools before recommending them for college-wide use. Administrators  
and  faculty  members  must  be  aware of  the  number  of  false  positives  and  false  negatives  these  detection 
tools report. Additionally, professional development on these detection tools should be ongoing as the  
advancement of technology will be ongoing.
For those who decide to use A I detectors, please consider the following questions:
Ł
 
What steps have you taken to substantiate a positive detection?
Ł
 
What other kinds of engagement with the student™s writing a rms your decision to assign a failing  
grade outside the A I detector™s claim t hat the text was A I generated?
Further, decisions about educational technologies should prioritize educators™ input over the  vendors  
providing t hese services. Using new technologies to surveil stu dents without ˜rst getting their consent and  
testing these tools violates students™ rights and sense of autonomy in classrooms. Educators may dier on  
what constitutes surveillance and what constitutes appropriate observation of the student learning process.  
Nevertheless, educators should always aim to reduce harm to how students can learn and grow using t hese  
technologies.
In  addition,  any new  technological  app roaches  to  academic  integrity  should  respect  legal,  privacy,  
nondiscrimination, and data rights of students. Any sharing of student writing with a company should at a  
minimum comply with students™ rights under FER PA. That includes scenarios where teachers are assigning  
students to submit their work to large language models like 
ChatGPT
 or Google Gemini (formerly 
Ba rd
),  and  
it also includes software designed to help the instructor verify t hat stu dents have written the work they have  
submitted, such as AI text detection and writing process tracking software.
V ERIFICATION TOOL S
In section I , we noted the value of policies oriented toward the writing process. Assessment practices  
that rely solely on evaluation of a discrete ˜nished product are particularly vulnerable to abuses of GA I.  
Thus,  programs  and  faculty  m embers are  encouraged  to  design  assessm ents  that  m easure  progressive  
steps toward learning and mastery. In addition to assigning steps in the writing process, many are turning  
to version-tracking software to create transparency around the process and help verify that a student  
wrote text. Beyond Google Doc s or Word version history, browser extensions and stand-alone apps are  
proliferating t hat report on the copy and paste history, time spent, and revision history of a document.
This approach raises questions about student consent, privacy, and data use. Educators have begun to  
debate this pract ice; some consider it a form of excessive surveillance. Others see it as akin to viewing  
staged writing process assignments or proctoring in-class writing . We oer the following recommendations:
Ł
 
Any software used for process tracking should be vetted for FER PA compliance and noncommercial  
use of student writ ing data.


  
11
Ł
 
Students with alternative-writing-process preferences that involve other apps or handwriting may use  
copy and paste for legitimate reasons, so we urge that any policy involving process-documentation  
software  accounts  for  accessibility  and  alternative-process  options.
Ł
 
We also urge recognition of the fallibility of this method. For example, a student could simp ly retype  
an A I text and insert revisions (or ask the A I for revisions to retype), and this would be undetectable  
through  the process-ob servation  software. Even  though  this  m et hod  can  be  circumvented,  we  
recognize t hat it may contribute to harm reduction. It may reduce the incidence of abuse of GA I  
because it makes unacknowledged GA I use logistically more dicult than simple copying and  
pasting .
Ł
 
Where possible, any use of document-history-tracking software should be combined with  
pedagogical pract ices that encourage students to reect on their writing processes.
Scenario  3
You™ve long used an annotated bibliography assignment as part of a research project, and this  
semester you™re concerned that it will lend itself to being easily completed by a GAI tool, robbing  
students  of  the  opportunity  to  practice  their  research,  critical  reading,  and  analysis  skills.  You  also 
worry that it will take more time to assess the originality of student work . You wonder just how you™re 
supposed to help your students develop these skills when so much of w hat you used to ask them to do  
seems to be ﬁbrokenﬂ by AI tools.
How can faculty members address cases in which they suspect students have used GA I in an academically  
dishonest way? An instructor who suspects students have ﬁcheatedﬂ on an assignment by using GA I needs  
to determine whether there is academic misconduct. Given these concerns, we recommend the following:
Ł
 
Meet with s tudents in a spirit of supportive, collaborative inquiry into their process, their learning, and  
the  barriers  they  face.
Ł
 
Try to remain open and curious and focused on moving forward to maximize the students™ learning .
Ł
 
Clarify what path forward you will oer students if indeed they did turn in text that was not their own  
and not labeled as produced by using GA I.
Ł
 
Ask students to describe their process in concrete terms.
Ł
 
Ask students ques tions about the ideas expressed in the writing and their choices as a writer.
Ł
 
Remind students of t he goals of the assignment and your desire that they get the most out of it.
Ł
 
Acknowledge the gray areas and sense of uncertainty given the newness of and rapid change in A I  
syste ms.
Ł
 
Consider clarifying in the syllabus policy from the beginning how you will proceed if you suspect  
unacknowledged and unau thorized use of GA I.


  
12
Re˚ections on Principles and Process Considerations
The MLA-CCCC Task Force recommends an approach to implementation and execution of policies (as  
guidance  or consequences)  that  balances  accountability  with education.  Policies  that  are  developed  
consultatively  throughout  the  institutional  spaces  (whether a  senate,  departm ent,  unit  or  o ce,  classroom,  
etc.) will more eectively serve those who are governed by them. Institut ions should consider some of the  
following questions as they develop their approach to policy writing:
Ł
 
Does this practice or policy aect some groups dierently than others?
Ł
 
Does this practice or policy support accountability?
Ł
 
Is this policy just? Does it disproportionately aect groups or individual s by material inequity, linguistic  
diversity, labor conditions, or other categories of identity?
First, we recommend that faculty members keep in the forefront of their minds the possibilities that
Ł
 
our own intuition about what text is A I generated is fallible, especially given the complexity and  
changing capacities of A I systems;
Ł
 
our judgment may be unconsciously biased against marginalized groups of students such as English  
language learners, students with disabilities, s tu dents who speak variants of English or seem not  
to have mastered Standard English, racially marginalized students, low- income students, and other  
groups;
Ł
 
software used to help instructors identify unacknowledged GA I , such as detection software or even  
software that attempts to verify human authorship, in most cases has not undergone peer-reviewed  
tests for bias against particular marginalized stu dent groups. There are stu dies, however, that suggest  
some systems do indeed wrongly ag marginalized students™ work as A I disproport ionately; and
Ł
 
some kinds of A I usage that seem obvious are not likely the only cases; students who are more  
technologically savvy and more priv ileged in other ways may be more likely to ˜nd ways to evade  
detection and to simulate patterns of student writ ing .
I I I. Policies for Faculty Use of GAI
Scenario  4
In a meeting of the department faculty, a graduate student representative of the student organization  
raises their hand during a discussion of AI tools and policies. They say that several of their fellow  
graduate student colleagues have approached them with a suspicion that faculty members are using  
large  language  models  like  
ChatGPT
 to assess and respond to their submitted assignments. They feel  
frustrated and hurt that faculty members are ﬁnot treating their work with respectﬂ and that their work  
has been submitted without their permission to a commercial tool.
Using arti˜cial intelligence to evaluate student work (i.e., high-stakes exams and essays) has been a  
decades-long debate in the humanities (Herrington and Moran). Automated evaluation is already used for  
written portions of standardized tests (Jargon). A key measurement of automated evaluation™s eectiveness  


  
13
is  how  well it  aligns  with  human  judgm ents.  Research has  shown  that  the  results of  these  technologies  vary.  
For examp le, some recent studies have shown that using automated feedback may help improve teachers™  
instructional practice (Demszky et al.); however, another recent study suggests that while automated  
feedback seems eective (aligned with human judgments), they ﬁ[indicate] that the use of automated  
feedback tools cannot be understood as a single consistent form of interventionﬂ (Fleckenstein et al. 1). In  
addition, automated writing evaluation tools may t hemselves continue to perpetuate linguistic bias based on 
th eir  received  t raining  data.
It is useful here to separate the question of evaluating quality to assign a grade from the question of  
providing feedback that supports a student™s development as a writer. Any consideration of the use of  
automated feedback must take into account not just accuracy of the feedback but also the eect on students  
knowing that the feedback comes from a machine and how that aects the student-teacher relat ionship. 
A known pedagogical reality is that the relationship with the teacher aects students™ learning of writing .  
Trust and transparency shapes how students value composed knowledge, and automated feedback may  
undermine t he signi˜cance of the inst ructor™s teaching through comments.
We must al so think about the impact of any automated feedback on the credibility of framing writing as  
meaningful communication between humans. If we are framing academic writing as an invitation to students  
to join a larger ongoing conversation, then providing human readers, including the teacher and peers, who  
respond and make meaning out of the text is essential.
Just as deploying GA I for critical inquiry and problem-solving requires careful evaluation from the human  
user, deploying arti˜cial intelligence for feedback requires careful evaluation by instructors. Formative  
automated feedback might be oered to students as a supplement to instructor and peer feedback. U nder 
instructor supervision, engagement with automated feedback might be used to further critical A I literacy.  
In some cases, automated feedback may be a useful starting point for eect ive instructor summative and  
formative assessm ents.  Neverthel ess,  institutions  and  departments  should  create  policies  that  describe  how  
faculty  m embers  may  use  arti˜cial  intelligence in  their  ins tructional  practice.  These  policies  should  provide  
explicit guidance and caution on the claims and oers from educational vendors of A I- infused tools that they  
provide better, eective, and faster feedback on students™ learning. The policies should also draw on and be  
consistent with ins titutional policies on acceptable use of technology and faculty codes of conduct.
These questions may persist as more of these A I- infused tools continually develop: Will automated feedback  
reect linguistic bias? How will feedback systems test for linguis tic bias in advance of their use? Our  
professional  organizations  have  established  standards  and  guidance  throu gh  docum ents  like  t he  Conference 
on College C omposition and Communication™s ﬁ
CCCC Statement on White Language Supremacy
ﬂ  (2021),  
Students™ Right to Their Own Language
 (initial approval  in  1 974),  ﬁ
This Ain™t Anot her Statement! This Is a  
DEMA ND for Black Linguistic Justice!
ﬂ (2020), and ﬁ
CCCC Statement on Second Language Writing and 
Multilingual  Writers
ﬂ (initial approval in 20 01). We a rm the importance of dedicated human attention to the  
ways algorithms can atten discourse, homogenize language, and stigmatize certain dialects of English,  
much to the detriment of the vibrancy of linguistic diversity (see Rettberg).


  
14
Use  of  GAI  for  Preparing  Course  Materials
There are a host of other purposes for which faculty members may desire to use text generation  
technologies. Many inuencers and ed tech companies are currently urging teachers to reduce their  
workload and improve their teaching by using GA I for instructional design, lesson planning, discussion  
questions, examp les, syllabus language, and other course materials. We note that guidelines for such  
use may be dierent than for student feedback. However, the principles below may be useful in guiding  
development of both kinds of policies.
Ł
 
Transparency.
 We a rm transparency as a central principle for any faculty use of A I. To support t he 
fundamental academic values around source citation, we must be able to reassure students that we  
will let them know if any text we present to them is generated using A I or not. If we do use generated 
text and label it as such, we should be ready to explain to students why that use of GA I is appropriate 
in context and supportive of their learning .
Ł
 
Fairness and Context.
 In the spirit of the ideal of moving toward common communities of  
knowledge-making, we recognize that perceived double standards could negatively inuence the  
learning environment and student motivation, if, for example, students were banned from using AI  
but faculty members were allowed to use it broadly. At the same time, we recognize that the policy  
around student writing must be informed by the purpose of that writing: stu dent learning . Policy  
around faculty members writing may dier depending on the context and purpose of that writing . The  
core question must be how faculty use of text generation would aect stu dent learning and whether  
it substitutes for writing where human authorship and intention are important. For example, if a faculty  
member uses a language model to draft a sample essay to illustrate a point, that is a context where  
the authorship or intention of the essay might not be critical; students learn from the way in which the  
text  illustrates  a  particular  concept.
Ł
 
Tiered Policy.
 Just as a tiered structure from inst itutional to department to class level is appropriate  
for student-focused academic integrity policies, such a tiered structure is needed to address the 
contexts that should inform policy around instruc tor use of GA I. Dierent guidelines may be more  
appropriate for automated feedback on lab reports, for example, than for au tomated feedback in ˜rst-
year  composition  courses.
Ł
 
Inclusion.
 At all of these levels, we urge collaborative decision-making inclusive of all stakeholders,  
including non-tenure-track  faculty  m embers,  faculty  m embers  wit h disabilities,  and  faculty  members  
who are marginalized for other reasons.
Ł
 
Labor.
 Such decision-making and discussions should include explicit discussion of labor concerns  
that inform educator interest in using GA I. Faculty workload aects the amount and quality of  
feedback  faculty  m embers  can  give.
Ł
 
E ducation.
 Discussion and education about emerging facult y practices involving AI and their possible  
bene˜ts and harms to students will be essential. Investment in faculty professional development  
around critical A I literacy is critical to productive and meaningful policy format ion.


  
15
I V. Considering GAI™s Impact on Key Policy Areas
In this section, we identify six key areas that GA I policy will aect, ˜rst summarizing each of these relevant 
areas and then advancing questions for further thinking that readers can consider as they are developing  
policy.
Ł
 
M ultilingu alism.
 All students should be allowed to use the dialects that represent their identity,  
style, and culture in English language classrooms, as argued ˜fty years ago in the Conference on  
College Composition and Communication™s inuential 
Students™ Right to Their Own Language
. 
More recently, research into anti -Black language discrimination has considered how the privileging  
of certain monolingual beliefs about writing eclipses other ideas about language and writing (Alim 
and Smitherman; Lyiscott). Yet research has shown that many GA I model s train on English, and  
white Standard English more speci˜cally (Ta and Lee). Questions to consider when setting policy: If  
students have a right to their own voice and language, what does it mean if that voice borrows and 
adapts from GA I to access and conform to white Standard English? How might policies privilege a  
particular language or dialect and shape the linguistic practices of students?  
Ł
 
Literacy.
 Policies  should  foster  user  literacy  about  GA I.  While  any  policy  makes  implicit  assumptions  
about its target audience, this is particularly fraught when it comes to new technologies. There is  
a tendency to assume younger generations are ﬁdigital nativesﬂ or that they somehow otherwise  
ﬁnaturallyﬂ get  new  technol ogies,  assumptions  that  are  not  sub stantiated  by  research (Banks;  
J ohnson-Eilola and Selber). But promoting literacy about GA I , rather t han as suming students  
understand it or banning it outright, is essential to helping students use it eectively to learn.  
Questions to consider when setting policy: How does the language about acces s and equity from  
earlier technological use policies inform more contemporary policy decisions? What eects do  
banning cert ain technologies for writing and reading have on disabled students? Moreover, what  
eects would such a ban have on ˜rst-generation or disadvantaged or minoritized students who are  
often marginalized in shared spaces for digital practice? In what way s does a bias against computer-
mediated work and knowledge already aect how GA I policies will be made and used?
Ł
 
Surveillance and  Policing.
 All forms of surveillance place st ress and pressure on individuals. A I  
technologies and language surveillance p resent a particularly complex situation. Placing students  
under a high-pressure surveilled writing situation can create negative feelings toward the writing  
process and undermine investment in transparency. Questions to consider when setting policy: 
Should student learning be observed through real-time writing eorts to verify authorship? How  
important is it for students to be authors of original work versus pro˜cient users of GA I writing  
tools? Should GA I policies be adapted for whether they are being eectively used (one way of  
measuring learning) versus whether they are used at all as a matter of ethic s and integrity? How  
have prev ious digital and writing studies, discussions of privacy, and punitive surveillance anticipated  
this discussion? How have studies regarding vulnerable populations addressed the issue of erasure  
within writing and cultural rhetorics? What do policies and practices based on surveillance and  
policing say about our baseline trust of students to do the work? What do they reveal about our own  
imagined relationship to our students and our role in their education?


  
16
Ł
 
Inte llectual Prop erty.
 Artists, writers, and scholarsŠhuman beings who t hink, have emotions, and  
respond to lived experiencesŠhave drawn upon cultural stores of preexisting material s for centuries  
to engage one another in thinking about t heir world, both intentionally and through unconscious  
inuence. Indeed, research in the late 1 990s on originality, copyright, remixing, reusing, open  
source  software,  and  free  access  to  cultural  artifacts  chall enged  notions  of  intellectual  property  
championed such uses (Buranen and Roy; Haviland and Mullin; Lessig; Schwartz; Thomas and Sassi;  
Vaidhyanathan). However, GA I is not a human being . Questions to consider when setting policy:  
In what ways have emerging IP issues around GA I been seriously considered by writing program  
administrators and other administrative ocials? How do institutions that ban collaboration in their  
campus-wide integrity policies approve of departmental policies that embrace some use of GA I as  
ﬁauthorized collaborationﬂ?
Ł
 
ﬁGoo dﬂ  Writing.
 Scholarship on assessing what counts as ﬁgoodﬂ writing has, over the last several  
decades, complicated the assumption that ﬁgood writingﬂ equals conformity to a standardized  
version of English (see Poe et al., ﬁLegalﬂ; Poe and Cogan; Poe et al., 
Writing  Assessment
;  Vee) .  
Researchers recognize that the ability of a writer (human or arti˜cial) to produce p rose according  
to standardized English is neither necessary nor sucient to call a text ﬁgood.ﬂ GA I technologies  
are not only displacing writing professional s in many careers (including translation, journalism, and  
law) but also aecting how writers feel about ownership of their writing, internalize convent ions,  
and express creativity (Baron, ﬁAIﬂ and 
Who
). In a 2023 column in 
Insi d e  Higher  Ed
, for examp le,  
J onathan Alexander points out the rich and purposeful place of language and writing, arguing that  
these are opportunities for learning to which students are entitled. Writing gives students intellectual  
and creative opportunities to develop and p lay while preparing them for careers that one day, if not  
already, may require skill with arti˜cial intelligence. Questions to consider when setting policy: What  
counts as knowledge and learning at the higher educational level? How has writing been used to  
structure social relationships and access to institu tional resources, as opposed to being both a site  
and a practice for learning?
Ł
 
Writing as a Process.
 Policies that simply assume a binary app roach to restricting or permitting GA I  
thus risk not t aking account of the realities of the writing process. This is because writing is most  
productively learned as a process rat her than a product, as research in the ˜eld of composition has  
long con˜rmed (Emig; Perl; Sommers; Ede and Lunsford). If the process begins in the mind of the  
originating aut hor, it continues through multiple iterations of drafting, feedback, revision, and eventual  
publication or evaluation. Questions to consider when setting policy: If a given policy prohibits GAI for 
particular phases (e.g ., invention, feedback) but allows it for others (e.g ., planning, revision), how does  
this inconsistency impact students? How can policy language acknowledge that these processes  
are not necessarily linear or uniform? What limitations should be placed on the visibility of stages in  
the process, so t hat students have a sense of autonomy when they reect on cumulative progress  
over time? How can the academic labor invested in the writing process be a subject of classroom  
discussion?


  
17
Co nclusio n
As a framework on policies and practices, this document continues an ever-growing conversat ion about  
the ethical and educational uses of A I tools, speci˜cally GA I at colleges and universities, including within  
programs, departments, and individual classrooms. The MLA-CCCC Task Force endeavors to provide  
reasonable approaches to this complex reality. We know institutions are wrestling with the realities of GA I.  
Institutions hope to ˜nd the right approaches that align with the goals of higher education, the value of  
academic freedom, and the passions and curiosities of students who come with their literacies, insights,  
and questions. In t his light, we have created what we hope will be a living document that sharpens and  
shapes administrators™ and instructors™ understanding of how GA I policy can be applied at their institutions  
and within their classrooms. Equally important, we recognize that GAI comes out of social context and is not  
going away. We want to fully comprehend and transparently adapt to this context, knowing its complexities  
and uncertainties. We hope that these guidelines and recommendat ions help our colleagues develop  
policies  around  A I.
Acknowledgments
The task force would like to thank the following participants of the Critical A I Literacy for Reading, Writing,  
and Languages Workshop for reviewing and providing helpful feedback and revision suggestions on this  
working  paper:  J oanne  Giordano,  Jason  Hendrickson,  Temptaous Mckoy,  Lilian  Mina,  Sherry  Wynn  Perdue,  
Judy  Ruttenberg,  Zhaozhe  Wang,  Jervette  Ward,  and Jen  William.
Works Cited and Consulted
Alexander, J onathan. ﬁStudents™ Right to Write.ﬂ 
Insi d e  Higher  Ed
, 22 Nov. 2023, 
www.insidehighered.com/
opinion/views/2023/1 1/22 /students-have-right-write-ai -e ra-opinion
.
Alim,  H . Samy,  and  Geneva  Smitherman.  
Articulate while  Black:  Barack Obama,  Langua ge,  and  Race  in  the  
US
. Oxford UP, 2012.
Banks, Adam. ﬁ2015 CCCC Chair™s Address: Ain™t No Walls behind the Sky, Baby! Funk, Flight, Freedom.ﬂ 
Col lege  Composition a nd  Commu nication
, vol. 67, no. 2, Dec. 2015, pp. 267Œ79.
Baron, Naomi S. ﬁA I in the Classroom Is a Problem: Professors Are the Solution.ﬂ 
The  Chronicle  of  Higher  
Education
, 3 Oct. 2023, 
www.ch ronicl e.com/a rticle/ai- in-the-classroom- is-a-proble m-professors
 
-are-the-solution
.
ŠŠŠ.  
Who Wrote This? How AI and the Lure of E˛ciency Threaten Human Writing
. Stanford UP, 2023 .
Bean, Christopher. ﬁ The A I Detect ion Arms Race Is On.ﬂ 
Wired
, 14 Sept. 2023 . 
www.wired.com/story/ai
 
-detection-chat-gpt-college-students/
.
Bender, Emily M., et al. ﬁOn the Dangers of Stochastic Parrots: Can Language Models Be Too Big?ﬂ 
FAc cT  ™21:  
Proceedings of  the  2021  ACM  Conference  on  Fairness,  Accountability,  and  Transparency
, 
 
1 Mar. 2021,  pp. 610Œ23 .
Buranen,  Lise,  and  Alice  Myers Roy.  
Perspectives  on  Pla giarism  and  Intellectual  Property  in  a  Postmodern  
World
. State U of New York P, 1 999.


  
18
Campbell, Mark, and Mlaan J ovanovi. ﬁDetecting Arti˜cial Intelligence: A New Cyberarms Race Begins.ﬂ 
Computer
, vol. 56, no. 8, 2023, pp. 10 0Œ 05, 
https://doi.org/10.1109/MC.2023.3279 446
.
Coldewey, Dev in. ﬁOpenA I Scuttles AI-Written Text Detector over ‚Low Rate of Accuracy.™ﬂ 
TechCru nch
, 
25July 2023, 
techcrunch.com/2023/07/25/openai -scuttles-ai -written-text-detector-over-low-rate-of
 
-accuracy/
.
Coley, Michael. ﬁGuidance on A I Detection and Why We™re Disabling Turnitin™s A I Detector.ﬂ 
Brightspace
, 
Vanderbilt U niversity, 16 Aug . 2023, 
www.vanderbilt.edu/brightspace/2023 /08/16/guidance-on-ai
 
-detection-and-why-we re-disabling-turnitins-ai -detector/
.
Darby, Flower, and James M. Lang . 
Sma ll  Teaching  Online:  Applying Lea rning  Science  in  Online Cl asses
. 
Jossey-Bass, 201 9.
Demszky, Dorottya, et al. ﬁCan Automated Feedback Improve Teachers™ U ptake of Student Ideas? Evidence  
from a Randomized Controlled Trial in a Large- Scale Online Course.ﬂ 
Education  Evaluation and  Policy  
Analysis
, 2023, p p. 1Œ23 . 
Sa ge  Journals
, 
journals.sagepub.com/doi/10.3102 /016237 37231169270
.
Ede, Lisa, and Andrea Lunsford. ﬁAudience Addressed / Audience Invoked: The Role of Audience in  
Composition Theory and Pedagogy.ﬂ 
Col lege  Composition a nd  Commu nication
, vol. 35, no. 2, 1 984,  
pp. 155 Œ71 . 
JSTOR
, 
https://doi.org/10.2307/ 358093
.
Emig,  Janet.  
The Composing Processes of Twelfth
. National Council of Teachers of English, 1 971 .
Fleckenstein, J ohanna, et al. ﬁAutomated Feedback and Writing: A Multi -level Meta-Analysis of Eects on  
Students™ Performance.ﬂ 
Frontiers  in  Arti˜cia l  Intel l igence
, vol. 6, July 2023, pp. 1Œ11 .
Foltýnek, Tomáı, et al. ﬁAcademic Plagiarism Detection: A Systematic Literature Review.ﬂ 
ACM  Computing  
Su rveys
, vol. 52, no. 6, Oct. 201 9, pp. 1Œ42, 
dl.a cm.org/doi/pdf/10.1145/ 3 3 45 317
.
Fong, J oss. ﬁA I Can Do Your Homework: Now What?ﬂ 
Vo x
, 12 Dec. 2023, 
www.vox.com/
videos/2023 /12 /12 /23998858/ai -chatgpt-ed ucation-ch eating
.
Goodlad, Lauren, and Sharon Stoerger. ﬁRutgers A I Council, Teaching Critical A I Literacies.ﬂ 
doc s.google
 
.com/document/d/1TAXqYGid8sQz8v1ngTLD1qZBx2rNKHeKn9mcfWbFzRQ /edit#heading=h
 
.kgds7i8l6uca
.  Accessed 22  Jan.  2024.
Haviland, Carol Peterson, and J oan A. Mullin. 
Who  Owns  This  Text?  Pla giarism,  Authorship,  and  Disciplinary  
Cu ltu res
. Utah State UP, 20 09.
Herrington, Anne, and Charles Moran. ﬁWhat Happens When Machines Read Our Students™ Writing?ﬂ  
Col l ege  Engl ish
, vol. 63, no. 4, 20 01, pp. 480Œ99.
ﬁHow Can Educators Respond to Students Presenting A I-Generated Content as Their Own?ﬂ 
OpenAI
, 
help
 
.openai.com/en/articles/8313 351-how-can-educators-respond-to-students-presenting-ai -generated
 
-content-as-their-own
.  Accessed 15 Jan.  2024.  
Jargon, Julie. ﬁBots Grade Your Kids™ SchoolworkŠand They™re Often Wrong .ﬂ 
Wall  Street  Journal
, 17 Nov.  
2020,  
www.wsj.com/articles/when-the-bot-that-grades-your-kids-schoolwork-earns
 
-an-f-11605618000
.
J ohnson-Eilola, Johndan, and Stuart A. Selber. ﬁPlagiarism, Originality, Assemblage.ﬂ 
Computers  a nd  
Composition
, vol. 24, no. 4, 20 07, pp. 375Œ403 . 
Science Direct
, 
https://doi.org/10.1016/j
 
.compcom.20 07.08.0 03
.


  
19
J ones, Natasha, et al. ﬁDisrupting the Past to Disrupt the Future: An Antenarrative of Technical  
Communication.ﬂ 
Technical Communication  Quarterly
, vol. 25, no. 4, 2016, pp. 211Œ29.
Lang,  Jam es M.  
Small Teaching: Everyday Lessons from the Science of Learning
. Jossey-Bass, 2021 .
Lessig,  Lawrence.  
Remix: Making Art and Commerce Thrive in the Hybrid Economy
. Penguin Books, 2008.
Liang, Weixin, et al. ﬁGPT Detectors Are Biased against Non-native English Writers.ﬂ 
Arxiv
, 10 July 2023, 
arxiv
 
.org/pdf/2304.02819.pdf
.
Long, Liza. ﬁNotes on 
ChatGPT
, Research, and Academic Integrity.ﬂ 
Pathw ays  to  Col l ege  Success
, CW I 101  
Leaders, 
c wi.pressbooks.pub/pat hwaystocollegesuccess/chapter/notes-on-chatgpt-and-research/
.
Lyiscott,  Jamila.  
Black Appetite. White Food: Issues of Race, Voice, and Justice within and beyond the  
Classroom
. Routledge, 201 9.
McDermot t, B. A I for Good: Exploring How Generative A I Can Support U niversal Design for Learning . Cyber  
Summit, 8 Nov. 2023, Ban Park Lodge, Ban, Alberta, Canada.
Mills, Anna, editor. ﬁA I Text Generators: Sources to Stimulate Discussion among Teachers.ﬂ 
WAC  
Clearinghouse
, 
https://bit. ly/A ITextEdu
.
ŠŠŠ. ﬁYou are a student. Your instructor gives you a choice: Would you rather write your essay in class  
or write it out of class with full keystroke-by-keystroke transparency about your activity in the  
document?ﬂ 
X
, 3 Jan. 2024, 
x.com/EnglishOER/status/1742574 0985958565 49?s=20
.
Perkins, Mike, et al. ﬁGame of Tones: Faculty Detection of GPT-4 Generated Content in U niversity  
Assessm ents.ﬂ  
Arxiv
, 29 May 2023, 
arxiv.org/abs/2305.1808 1
.
Perl, Sondra. ﬁThe Composing Processes of U nskilled College Writers.ﬂ 
Research in the Teaching of English
, 
vol. 13, no. 4, 1 979, p p. 317Œ36.
Poe, Mya, and J ohn Aloysius Cogan, Jr. ﬁCivil Rights and Writing Assessment: Using the Disparate Impact  
Approach as a Fairness Methodology to Evaluate Social Impact.ﬂ 
Journal  of  Writing  Assessment
, 
vol.9, no. 1, 
https://escholarship.org/uc/item/08f1c307
.
Poe, Mya, et al. ﬁ The Legal and the Local: Using Disparate Impact Analysis to U nderstand the Consequences  
of Writing Assessment.ﬂ 
Col lege  Composition a nd  Commu nication
, vol. 65, no. 4, June 2014, pp.588Œ
611 .
Poe, Mya, et al. 
Writing A ssessment, Social Justice, and the Advancement of Opportunity
.  WAC  
Clearinghouse,  2018,  
wac.colostate.edu/books/perspectives/assessm ent/
.
Razi, Salim, and Burcu Özge Raz. ﬁIDOA 2023: Ethical Implementation of A I in the Process of  
Academic Writing .ﬂ International Day of Action for Academic Integrity, 18 Oct. 2023, online.  
Y ouTu be
, uploaded by IC A I International Center for Academic Integrity, 24 Oct. 2023, 
yo utu.be/
XlwQUFPtwag?si=SIEXyIHDO4xH2LJL
.
Rettberg, J ill.  ﬁ
ChatGPT
 Is Multilingual but Monocultural, and It™s Learning Your Values.ﬂ 
J ill/txt
, 6 Dec. 2022,  
jilltxt.net/right-now-chatgpt- is-multilingual-but-monocultural-but- its-learning-your-values/
.
Sayers, David. ﬁA Simple Hack to 
ChatGPT
-Proof Assignments Using 
Google  Drive
.ﬂ  
Times Higher Education
, 
25 May 2023, 
www.tim eshighereducation.com/campus/simple-hack-chatgpt proof-assignm ents
 
-using-google-drive
.
Schwartz,  Hillel.  
The Culture of the Copy: Striking Likenesses, Unreasonable Facsimiles
. Zone Books, 1 996.


  
20
Silverstro, John J. ﬁRemember Then Recommend: Critically Engaging Spell C hecker Algorithms and Ot her  
Text Recommender Systems as Memory Infrastructures.ﬂ 
Col l ege  Engl ish
, vol. 86, no. 1, Sept. 2023,  
pp.  59 Œ88.
Sommers, Nancy. ﬁRevision Strategies of Student Writers and Ex perienced Adult Writers.ﬂ 
Col l ege  
Composition  a nd  Commu nication
, vol. 31, no. 4, 1 980, pp. 378Œ88. 
JSTOR
, 
https://doi
 
.org/10.2307/ 356588
.
Stanford, Daniel. ﬁAnnotated Syllabi Polices for Generative A I - Daniel Stanford.ﬂ 
doc s.google.com/
spreadsh eets/d/1CfYfFe3Zp3vP2bioA M5 MrW0yk1857R2SYJnKojD15tQ /edit#gid=0
.  Accessed  23  Jan.  
2024.
ŠŠŠ. ﬁ The Best A I Syllabus Policies I ™ve Seen So Far.ﬂ 
Daniel  Stanford™s  Substack
,  16  Jan.  2024,  
danielstanford.sub stack.com/p/the-best-ai -syllabus-policies- ive
.
Ta, Regina, and Nicol Turner Lee. ﬁHow Language Gaps Constrain Generative A I Development.ﬂ 
Brooking s  
Institution
, 24 Oct. 2023, 
www.brookings.edu/art icles/how-language-gaps-constrain-generative-ai
 
-development/
.
Thomas, Ebony Elizabeth, and Kelly Sassi. ﬁAn Ethical Dilemma: Talking about Plagiarism and Academic  
Integrity in the Digital Age.ﬂ 
The  English Journal
, vol. 10 0, no. 6, 2011, pp. 47Œ53 .
Thompson, Stuart A., and Tiany Hsu. ﬁHow Easy Is It to Fool A.I.-Detection Tool s?ﬂ 
The New York Times
, 
28June 2023, 
www.nytim es.com/interactive/2023/0 6/28/technology/ai -detection-midjourney-stabl e
 
-diusion-dalle.html
.
Trust, Torrey. ﬁA I Text Detectors (aka A I Plagiarism Detectors and A I Content Detectors).ﬂ Nov. 2023 . 
doc s
 
.google.com/presentation/d/ 1ADoqCSeBFaspv0 qqiH q Qm sdwazdqLjpASp JTutgmcNU/edit# slide=id.p
.
ŠŠŠ. ﬁEssential Considerations for Addressing the Possibility of A I-Driven Cheating, Part 1 .ﬂ 
Faculty  Focus
, 
2Aug . 2023, 
www.facultyfocus.com/articles/teaching-wit h-technology-articles/essential
 
-considerations-for-addressing-the-possibility-of -ai -driven-cheating-part-1/
.
ŠŠŠ. ﬁEssential Considerations for Addressing the Possibility of A I-Driven Cheating, Part 2.ﬂ 
Faculty  Focus
, 
4Aug . 2023 . 
www.facultyfocus.com/articles/teaching-wit h-technology-articles/essential
 
-considerations-for-addressing-the-possibility-of -ai -driven-cheating-part-2 /
.
Tzanni, Penny. ﬁDiscrimination and Nat ive-Speakerism in English for Academic Purposes (EA P).ﬂ 
Studies  in  
Technology  Enha nced  Lea rning
, vol 2, no. 3, 16 May 2022, 
https://doi.org/10.21428/8c225f6e.755eca93
.
ﬁ The Use of Generative Arti˜cial Intelligence Technologies Is Prohibited for the NIH Peer Review Process.ﬂ  
Grants  and  Funding: NIH  Central  Resource  for  Grants  and  Funding  I nformation
, National Institutes of 
Health, 23 June 2023, 
grants.nih.gov/grants/guide/notice- ˜ les/NOT-OD-23-149.html
. 
Vaidhyanathan,  Siva.  
The Anarchist in the Library: How the Clash between Freedom and Control Is Hacking  
the Real World and Crashing the System
. Basic Books, 20 04.
Vee,  Annette.  
Cod ing Literacy:  How  Computer  Progra mming  Is  Changing  Writing
. MIT Press, 2017.
Watkins,  Marc.  ﬁ ‚Humanmarking™: Authenticity  throu gh  Surveillance.ﬂ  
Rhetorica:  Notes  from  a  Nontraditional  
Student  Turned  Educator:  Culture,  A I, Education
, 24 Sept. 2023, 
ma rcwatkins.sub sta ck.com/p/
humanmarking-authenticity-through
.
Weber-Wul, Debora, et al. ﬁ Testing of Detection Tools for A I-Generated Text.ﬂ 
International Journal  for  
Education  Integrity
, vol. 1 9, article no. 26, 2023, 
https://doi.org/10.10 07/s4 0979 - 023- 0 0146-z
.


  
21
Resources
ADE  Guidelines  for  Clas s  Size  and  Workload  for  Colle ge  and Universit y  I ns t ruc tors  of  English:  A  
St atemen t  of  Policy
ﬁ
A Blueprint for an AI Bill of Rights for Education
,ﬂ
 by Kat hry n Conrad
CCCC St atement on Preparing Teachers of College Writ ing
Design  Just ice
Et hical  Framework  for  Generat ive  AI:  Principl es  in  Educat ion
, by Harry Pickens and ChatGPT
How to Talk to Your Students abou t AI
, by Annet te Vee and Tim Laquint ano
ﬁImage of AI Use Levels,ﬂ
 by  Eliana Elkhoury
Internat ional Center  for  Academic  Inte gri ty
Principl e s  for  t he Po s tse condary  Teaching  of  Writ ing,
 by Conference on College Composit ion and  
Com municat ion
Sy llabi Policies for AI Generat ive Tools
, edited by Lance Eaton