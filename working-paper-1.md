---
title: Working Paper 1
---

> **Source:**  
> _working paper 1_  
> © 2023–2024 Modern Language Association of America and Conference on College Composition and Communication  
>  
> Reproduced for educational, non-commercial use under fair use guidelines.  
> Original: [https://aiandwriting.hcommons.org](https://aiandwriting.hcommons.org)


MLA-CCCC Joint Task Force 
 
on  Writing  and  AI  Working  Pap er:  
Overview of the Issues, Statement 
 
of  Principles, and  Recommendations
M LA -CCCC  Joint  Task  Force  on  Writing and  AI
July 2023
© 2023 Modern Language Association of America and Conference on Co llege Comp osition and Communication


  
2
Antonio By rd (Universit y of Missouri, Kansas Cit y)
Le onardo  Fl ores  (Ap p alachian  St ate  University)
Dav id  Gre en  (How ard  Universit y)
Holly  Has sel  (Michigan  Te chnol o gical  Universit y);  co chair
Sarah  Z.  Johnson  (Madison  Colle ge)
Mat t hew Kirschenbaum  (Universit y  of  Mary land, Coll e ge  Park)
A.  Lo cket t  (indep enden t  scholar)
Elizabeth Mat hew s Losh (William and Mary Universit y); cochair
Anna Mills (College of Marin)
MLA-CCCC  Joint  Task  Force
 
on  Wri ting  and AI  Members


  
3
Contents
In t roduc t ion
 
˜
Background
 
˚
His tory,  Nomenclature,  and  Key  Concepts
 
˚
Risk s to  Language,  Literature,  and  Writ ing  Ins t ruct ion  and  Scholarship
 
˛
Risk s to s tudents
 
˝
Risk s  to  teachers
 
˝
Risk s to programs and the profes sion
 
˝
Bene˙ts  to  Language,  Literature, and  Writ ing  Ins t ruc t ion  and  Scholarship
 
ˆ
Bene˙ts  for  language  ins t ruct ion
 
ˆ
Bene˙ts  for  literary  s tu dies
 
ˇ
Bene˙ts  for  writ ing  ins t ruct ion
 
ˇ
Principles  and  Re commendations
 
˘
Acknowle d gmen ts
 
˘
Work s Cited and Further Reading
 
˘
Appendix: Responses to t he MLA -CCCC Joint Task Force Ques t ionnaire
 
˘˜
MLA-CCCC Joint Task Force on Wri ting and AI 
 
Working Paper: Overview of the Issues, 
 
Statement  of  Principles ,  and Recommendations


Introdu ction
As generative arti˙cial intelligence (A I) technologies become widely available as writing aids, the Modern  
Language Association and the Conference on College Composition and Communication, a chartered  
conference of the National Council of Teachers of English, a rm our common values as organizations  
serving p rofessional educators. We believe that writing is an important mode of learning that facilitates the  
analysis and synthesis of information, the retention of knowledge, cognitive development, social connection,  
and participation in public life. We believe that writing itselfŠfrom the earliest impression of marks on clay to  
recent word processors with autocorrect, research citation, and other aidsŠhas always been a technology 
and, as such, is always open to new technologies. However, we also believe that human endeavors are  
at the heart of a humanities educationŠand education more broadlyŠand are concerned that support for  
writing and language learning programs could be under threat.  
We a rm t hat the term 
writing
 describes a process as well as a product and that the labor of students,  
teachers, and writing professionals should be credited and compensated. We believe that higher education™s  
speci˙c institutional role of credentialing the achievements of students as individuals means that generative  
A I cannot simply be used in colleges and universities as it might be in other organizations for eciency or  
other purposes. To this end, we believe the primary work of educators is to support students™ intellectual  
and social development and to foster exploration and creativity rather than to surveil, discipline, or punish  
students.
This working paper explains the relevant history, nomenclature, and key concepts to our profession. U nder  
this framework, the paper declares t he broad risks and potential bene˙ts of arti˙cial intelligence to language,  
literary, and writing scholarship and instruction and the ways generat ive A I will aect all of us in higher  
education: students, scholars, instructors, administrators, and sta members. The paper then suggests  
principles and recommendations for creating policies, guidelines, and pract ices that draw on our strengths as  
teachers  and  scholars.  
Future working papers will focus on the other important topic s raised by large language models (LLMs) in  
more detailŠfor example, ethic s, citation practices, linguis tic diversity, reading, pedagogical implications,  
language instruction, and others as they emerge. This working paper recognizes that our understanding of  
writing and how it is taught requires reenvisioning in the light of what looks to be seismic shifts warranted by  
LLMs.  
Working Paper: Overview of the Issues, 
 
Statement  of  Principles ,  and Recommendations
© Modern Language Association of America and Conference on Co llege Composition and Comunication


  
5
B ackgroun d
The MLA-CCCC J oint Task Force on Writing and A I (TF), formed in December of 2022 by the executive 
leadership of the Modern Language Association and the CCCC Executive Commit tee, was charged as  
follows:  
Ł
 
taking stock of t he current state of the is sue and identifying implications for teachers, students,  
organizations,  and  scholars
Ł
 
creating community  for  m embers  to  share  resources
Ł
 
creating resources that will synthesize, set professional standards, and make recommendations or  
provide  guidance  to  m embers
Ł
 
supporting and mapping out promising directions of scholarly interest for learning more about t he 
issue
The group convened on a biweekly basis, surfacing key issues and developing priorities. After developing  
a web presence, the group created a resource page and developed a questionnaire under the auspices  
of the MLA and CCCC to gather input from educators. In spring 2023, the MLA and CCCC distributed the  
questionnaire to learn more about concerns, questions, and issues that LLMs raise for writing, language, and  
literature educators. The questionnaire, as well as responses from reviewers (acknowledged at the end), has  
helped the TF identify priorities for developing resources. A high-level overview of the responses is available  
in  the  appendix.  
As a ˙rst step toward these charges, the TF is issuing this working paper, the ˙rst of an anticipated several  
working papers to begin a conversation and establish principles as the organizations move forward in an era  
of rising use of generative A I technologies for educational, scholarly, commercial, and public purposes.  
History, Nomenclature, and Key Concepts
Theorizing computers as intelligent, and even sentient, has long been tied to their ability to produce writing  
(such as Christopher Strachey™s 
Love Letters
 in 1 952), and interact with human beings in conversation (such  
as  J oseph  Weizenbaum™s  
ELIZA
 in 1 964). Members of the Modern Language Association and the College  
Conference on Composition and Communication have likewise been using and working with automatic text 
generation for decades, a corpus of research that has provided critical context for this group™s work.
Generative arti˙cial intelligence is often conated with art i˙cial 
genera l
 intellig ence  (AGI),  which is  the  
human-like, seemingly sentient A I that is still the stu of science ˙ction. 
Generative  A I
, by contrast, refers  
to computer sy stems that can produce, or generate, various forms of t raditionally human expression, in the  
form of digital content including language, images, video, and music. LLMs are a subset of generative AI  
used to deliver text-based formats like prose, poetry, or even programming code. The GPT grouping of LLMs  
currently enjoys the most public recognition, but there are others available; GPT itself st ands for generative  
pre-trained transformer, with each piece of that nomenclature bearing a speci˙c technical meaning .  


  
6
For our purposes it is enough to say that in 2018 the nonpro˙t OpenA I developed the means to yoke  
generative pre-trained models to the so-called transformer architecture introduced by Google in the  
previous  year,  thus  delivering  dramatic  increases  in  performance.  The  widely  discussed  
ChatGPT
 is  a  
speci˙c application of GPT-3 (now GPT-4), released in late 2022 by OpenA I. It combines an easy-to-access  
browser interface with a chatbot style of interaction, whereby a user can enter a series of discursive prompts  
and engage with the outputs of the model in an ongoing dialogic stream.
LLMs work by using statistic s and probability to predict what the next character (i.e., letter, punctuation mark,  
even a blank space) is likely to be in an ongoing sequence, thereby ﬁspellingﬂ words, phrases, and entire  
sentences and paragraphs. It is not unlike autocomplete, but more powerful. LLMs are trained on vas t bodies  
of preexisting text (such as content from the Internet), which, to some extent, predetermine their output. All  
of the text a model generates is original in the sense that it represents combinations of letters and words  
that generally have no exact match in the training documents, yet the content is also unoriginal in that it is  
determined by patterns in its training data. The same language model may generate a variety of dierent  
sequences in response to the same input prompt. A model cannot reliably report on which sources in its  
training data cont ributed to any given outpu t. All of this combines to make the output of LLMs qualitatively  
dierent from any other form of text, even texts that might have been computer generated according to  
some other method. It should be noted that given the assortment of software applications drawing on LLMs,  
presenting them  through  dierent  user  interfaces  to  oer  various  aordances,  they  are  also unavoidable.
Although it is often tempting to speak in terms of what an LLM is ﬁdoingﬂ or ﬁintendingﬂ or even ﬁthinking,ﬂ  
what we are witnessing is the production of word sequences that look like intentional human text through  
a process of statistical correlation. As the models are re˙ned, expand their language corpora, and draw on  
greater computational power, their outputs mimic the writ ing of sentient humans more convincingly. LLMs do  
not, however, ﬁthinkﬂ in the way that we would de˙ne such an ac tiv ity as it takes place in human cognition.
Risks  to  Language,  Literature,  and  Writing  Instruction and  Scholarship
The risks and threats to students, teachers, and t he profession are real and p rofound. Societal conversations  
are underway as well about the costs of LLMs, including the spread of misinformation, biased outputs,  
privacy and copyright violations, and env ironmental costs. All of these concerns aect our students and  
should inform our response as educators. We will focus here on potential costs speci˙c to our goals as  
educators and scholars and to the goals of our professional roles.
Some of the immediate risks posed by LLMs are to the interactional and human components of teaching,  
research, and s tu dent engagement. Student reading practices can become uncritically au tomated in  
ways that do not aid critical writing instruc t ion or faculty assessment approaches. The increased use and 
circulation of unveri˙ed information and the lack of source transparency complicates and undermines the  
ethic s of academic research and trust in the research process. Additionally, although using LLMs to collect  
and synthesize p reexisting information may provide students with model s of writing and analysis, such  
models  rep roduce  biases  through  the  attening  of  distinctive  linguistic,  literary,  and  analytical  approaches.  


  
7
Risks to students
Ł
 
Students may miss writing, reading, and thinking practice because they submit generative A I outputs  
as their own work or depend on generative A I summaries of texts rather than reading .
Ł
 
Students may not see writing or language study as valuable since machines can mimic these skills.
Ł
 
Students may ex perience an increased sense of alienation and mistrust if surveillance and detection  
approaches  meant  to  ensure  academic  integrity  are  undertaken.  Such approaches  have  been  proven  
unreliable and biased; they can produce fal se positives that could lead to wrongful accusations,  
resulting in negative consequences for the students.
Ł
 
Students may face increased linguistic injustice because LLMs promote an uncritical normative  
reproduction of s tandardized English usage that aligns wit h dominant racial and economic power  
structures. Worldwide, LLMs may also perpetuate the dominance of English.
Ł
 
Students may have unequal access to the most elite tools since some students and institutions will  
be able to purchase more sophisticated versions of the technologies, which may replicate societal  
in equalities.  
The above risks could hurt marginalized groups disproportionately, limiting their ability to make autonomous  
choices  about  t heir  expressive  possibilities.
Ri sks  to  teachers
Ł
 
Teachers may be asked to make signi˙cant changes to their practice without adequate time, training,  
or compensation for their labor. This has part icular implications for college writing instructors who  
work in contingent positions (adjunct faculty, graduate teaching assistants, and full-t ime, non-tenure-
track faculty), who make up the vas t majority of writing instructors and work in often precarious and  
under-supported conditions.
Ł
 
Teachers may lack adequate support and up-to-date training to understand LLMs as they relate to  
our  disciplines.
Ł
 
Teachers will need to spend time and energy developing critical A I literacy (that is, literacy about  
the nature, capacities, and risks of A I tools as well as how they might be used), which will divert their  
attention away from other teaching practices and course content unless adequate resources are 
given to build it into the curriculum.
Risks to p rograms and the p rofession
Ł
 
The public v iew of writing or language study may be seen as less valuable since machines can mimic  
these skills. People may believe that generative AI replaces the develop ment of critical thinking,  
composing, proces s knowledge, and the metacognition that writing helps stu dents develop.
Ł
 
Institutions may st ruggle to plan and provide for the kind of labor and resources needed to  
m eaningfully  respond  to  these  challenges.


  
8
Ł
 
Academic values around giving credit to sources may be comp romised because LLMs can™t or don™t 
point to the sources in their training data that shape their outputs.
Ł
 
U neven access  to  A I  text  generators  may  increase  inequities  between  scholars  of  dierent  
institutions or countries.  
Ł
 
The rapid changes in the technology and tool s available will make it dicult for institutions to keep  
policies  updated.
Ł
 
Variation in policies among instructors, departments, and institutions could make it hard for students  
to anticipate what writing skills and pract ices will be needed or acceptable in their next class.
Ł
 
Contingent faculty may be excluded from top-down decision making on generative A I yet  
simultaneously  be  expected  to  carry  out  labor- intensive  policies  and  teach  critical  A I  literacy.
Ł
 
Academic administrators may seek to increase class sizes or modify workloads based on perceived 
eciencies created by A I. This has t he potential of aecting jobs in areas that support or require  
writing ins truction and support.
Ł
 
Reliance on  A I-generated  analysis  and  writing  by  scholars  can  undermine  the  wide  range  of  research  
practices, including  research,  writing,  and  peer  review,  that  characterize  scholarship.
Bene˜ts  to  Language,  Literature,  and  Writing  Instruction  and  Scholarship  
While  acknowledging  the  inherent  pitfalls  of  generative  A I ,  the  technology  aords  enormous  potential  
bene˙ts. It has the promise to democratize writing, allowing almost anyone, regardless of educational  
background, socioeconomic advantages, and specialized skills, to participate in a wide range of discourse  
communities.  These  technologies, for  example,  prov ide  potential  bene˙ts to  student  writers  who  are 
disabled, who speak languages other than English, who are ˙rst-generation college students unfamiliar wit h 
the convent ions of academic writing, or who struggle with anxiety about beginning a writing project. They  
also augment the drafting and revising processes of writers for a variety of purposes.
Because  of  the  power  of  LLMs,  these  technologies  can  also  contribute  to  literary  study in  digital  spaces. 
LLMs can detect layouts, summarize text, extract metadata labels from unstructured text, and group similar  
text together to enable search (see Miller). In the f uture, data in large corpora of textsŠsuch as those  
availa ble  at 
Project  Gutenberg
Šcould  be  cleaned  and  standardized  by  automated  processes  that  use  LLMs.  
More import ant, this data could be quickly placed into a spreadsheet format that enables more ambit ious  
digital  humanities  projects  for  those  without  advanced  programming  skills.  LLMs  prov ide  a  resource  for  
synthesizing broad and varied documents and textual information. They can collect and organize informat ion  
such as dates, authors, and book titles in ways that can make the research and reading process quicker and  
dierent ly  accessible.  
Bene˜ ts  for  language  instruction
Ł
 
Language students can use LLMs to create translations that include explanations and wording  
options.


  
9
Ł
 
Language students can develop expertise even while using generative A I. Although it may be used  
to produce a rough draft of a translation, re˙ning such translations will still require knowledge about  
language choices, especially with literary works.
Ł
 
Language students can ask LLMs questions about a text in another language.
Ł
 
Language teachers can use generative A I to quickly come up with examples (Poole).
Bene˜ ts  for  literary  studies
Ł
 
Students can use LLMs as instruments for creative wordplay.
Ł
 
Students with a range of technical expertise can use LLMs, which can be prompted to produce code,  
to create electronic literature and digital writing .
Ł
 
Teachers can train and prompt LLMs to respond to speci˙c literary passages as an aid to class  
discussions.
Ł
 
Teachers of literature can use LLMs to produce imitations of authors™ styles and thematic concerns,  
assisting in lessons on t hese topic s.
Ł
 
Teachers and students can use LLMs to produce sample texts following established or innovative  
constraints, such as meter, rhyme, alliteration, and poetic and narrative forms.
Ł
 
Teachers and students can use LLMs to provide basic interpretations of literary texts, which can  
serve as low stakes launching points for discussion.  
Ł
 
Students  and  teachers  can  ask  LLMs  about  literary  works  dealing with  similar  them es  because  LLMs  
have access to massive amounts of information about dierent writers across literary periods and  
nationalities.
Bene˜ ts  for  writing  instruction
Ł
 
Students can use LLMs to help stimulate thought and develop drafts that are still the student™s own  
work and to overcome psychological obstacles to tackling invention and revision. When used in  
these ways, LLMs have the potential to act as literacy sponsors to emerging academic writers.
Ł
 
Students can use generative A I to produce creative materials when developing multimodal writing  
projects that communicate in modes other than written text, since generative A I can process data  
involving s till images, sound, and moving images.
Ł
 
Teachers can integrate LLMs into the writ ing process and enhance stu dents™ rhetorical knowled ge,  
critical thinking, and knowledge of conventions.
Ł
 
Teachers can use LLMs to oer a practical demonstration of some key rhetorical concepts that have 
inuenced writing and rhetoric studies, especially as related to questions of process, praxis, and the  
construction of meaning .
Ł
 
Teachers  can  use  LLMs  to  provide  models  of  written  prose t hat  can  be  used  to  highlight  dierences 
in genre, tone, diction, literary s t y le, and disciplinary focus. 


  
10
Ł
 
Teachers  can  use  LLMs  to  oer  new  processes  for  students  developing  multimodal  writing  genres  
since  LLMs  have  the  capability  to  p rocess  multimodal  inputs  and  outputs.
Ł
 
Teachers  can  use  LLMs  to  provide  course  content  that  bridges  the  gap  between  writing  across  
disciplin es.
Ł
 
Teachers  can  use  LLMs  to  quickly  generate  dierent  models  of  response  and  stimulate  discussion  
about various approaches to a writing prompt. These technologies allow instructors to ﬁshowﬂ as well  
as ﬁtellﬂ what dierent writing s trategies look like.
Ł
 
Teachers and students can use LLMs to complement existing tools for English language learnersŠ
such as usage dictionaries, grammar checkers, language tutorialsŠto ex perience success more  
rapidly in their writing eorts.
Ł
 
Writers who come from diverse and various linguistic and educational backgrounds may bene˙t from  
the more sophisticated grammar, style, and genre editing capabilities of LLMs by receiv ing access to  
the ﬁlanguage of power.ﬂ
Principles  and  Recommendations  
As organizations working together, we urge educators to respond out of a sense of our own strengths rather  
than operating ou t of fear. Rather than looking for quick ˙xes, we should support ongoing open and iterative  
processes to develop our responses. At the institutional level, policy should be accompanied by education  
about A I; when creating policy, institutional actors must prioritize bot h ethical conduct and the mission of  
higher  education.
As LLMs evolve in predictable and unpredictable ways, the organizations oer the following principle-driven  
recommendations:
1.
 
Provide support for teachers as we adapt our teaching methods and material s and respond to the  
complexity of issues and labor involved. Such support should be at multiple levelsŠfrom institutions  
and  organizations,  programs,  departm ents, and  school  districts.  Such  resources  and  support  should  
be compatible with the values outlined at the start of this statement.
2.
 
Center the continued teaching and learning of writing on writers and the inherent value that writing  
has as a mode of learning, exploration, and literacy development for all writers.  
3.
 
Create guiding documents, guiding materials, and resources for students and teachers that can be  
a foundation for policy and discussions of best practices, one t hat emphasizes the value of process-
focused instruction and activities to the cont inued development of students™ intellectual and literate 
lives. Students, teachers, and institutions need to understand the ethical, environmental, and labor  
implications t hat LLMs introduce as well as issues of copyright, data use, and privacy.
4.
 
Focus on approaches to academic integrity that support students rather t han punish them and that  
promote a collaborative rather than adversarial relationship between teachers and students. We urge  
caution and reection about the use of A I text detection tools. Any use of t hem should consider their  


  
11
aws and the possible eect of false accusations on students, including negative eects that may  
disproportionately aect marginalized groups.
5.
 
Develop policy language around A I by promoting an ethic of t ransparency around any use of AI  
text that builds on our teaching about source citation. For example, most A I generators produce a  
transcript of t he interaction with the user, which can be reproduced as documentation.
6.
 
Formulate policy that can educate about AI and help frame how campuses and communities respond  
to or take up A I and writing challenges and opportunities. We call for faculty involvement in the  
formation and evaluation of policies about A I rather than a top-down approach. We adv ise the use  
of an iterative policy process where we continue to reect and revise based on feedback as the  
technology  and  our  thinking  about  it  evolve.
7.
 
Use caution about responses that emphasize surveillance or restrict ions on the writing proces s 
that make the conditions of writing for class radically dierent from writing conditions students will  
encounter in  other  classes,  work environm ents,  and  their  personal  lives.
8.
 
Prioritize the development of critical A I literacy in faculty leaders and higher education administrators.  
By this we mean not just how A I models work but also about the risk, rewards, capacities, and  
complications of A I tools. We support allocation of more resources for developing critical literacy  
among teachers and students around the nature and pitfalls of text generators. Critical A I literacy is  
now part of digit al literacy, and students and teachers should be made aware of bias and inaccuracy  
in model outpu ts and the particular vulnerability of students who may not yet have sucient  
expertise to critically evaluate language model outputs, including seeing them as sentient.  
9.
 
Develop critical A I literacy in publishers and editors. Publishers and editors would be well served  
to develop critical A I literacy since they may encounter manuscripts that incorporate computer  
generated texts, both with LLMs and with artisanal software. We support the development of  
policy by leaders in scholarly communication (e.g ., the Committee on Publication Ethic s) alongside  
humanities-speci˙c policy in relat ion to research and publicat ion in these ˙elds, noting that the ˙eld  
of electronic literature has decades of experience publishing and critically assessing such work.  
10.
 
Dedicate t ime and resources to considering new guidelines for faculty use of A I by stakeholders and  
leaders to fully engage with the implications. New A I tools like 
ChatGPT
 and others produce both  
opportunities for eciency and new labor attached to educating, evaluating, and supporting learners.
11.
 
Expand institutional investment in writing instruction so that students can better assess how LLMs  
are constructed, trained, and deployed and learn to writeŠand rewriteŠthe instructions to these  
platforms for composing, a process often described as prompt engineering, drawing on existing  
expertise  in  rhetorical  knowledge.  
12.
 
Communicate with students, colleagues, and the public about the continuing value of writing to  
develop thinking .
Ultimately, this ˙rst statement from the MLA-CCCC task force calls for constructive and collaborative  
approaches to A I and writing and recognizes the strengths that our ˙elds jointly bring to the quest ions at  
hand. We are called upon to do some reimagining and some revisiting of commonplaces of our ˙elds. We  


  
12
are up to t his task if we do so with care, dialogue, reection, and humanity, all of which are central to the  
allied  ˙elds represented  by  our  organizations.
Acknowledgments
Troy Hicks, Matt Pavesich, and Anuj Gupta, as well as the MLA Committees on Academic Freedom and  
Professional Rights and Responsibilities, Contingent Labor in the Profession, and Information Technology,  
generously read a draft of the working paper and provided valuable input.
Works Cited and Further Reading
Bali, Maha. ﬁWhat I Mean When I Say Critical A I Literacy.ﬂ 
Re˜ecting  Al lowed
, 1 Apr. 2023, 
blog .mahabali.me/
educational-technology-2 /what- i -mean-when- i -say-critical-ai -literacy
/.
Bender, Emily, et al. ﬁOn the Danger of Stochastic Parrots: Can Language Models Be Too Big?ﬂ 
FAc cT  ™21:  
Proceedings of  the  2021  ACM  Conference  on  Fairness,  Accountability,  and  Transparency
, Mar. 2021,  
pp.  610Œ23 .  
ACM  Digital Library
, 
https://doi.org/10.1145/ 3 442188.3445922
.
Bhatia, Aatish. ﬁLet Us Show You How GPT WorksŠUsing Jane Austen.ﬂ 
The New York Times
, 27 Apr. 2023,  
www.nytim es.com/interactive/2023/04/26/upshot/gpt-from-scratch.html?smid=nytcore- ios-share&refe
rringSource=articleShare
.
ﬁEthical Guidelines on the Use of Art i˙cial Intelligence and Data in Teaching and Learning for Educators.ﬂ  
European  Educat ion Area
, European Commission, 25 Oct 2022, 
ed ucation.ec.europa.eu/n ews/
ethical-guidelines-on-the-use-of -arti˙cial- intellig ence-and-data- in-teaching-and-learning-for
 
-educators
.
Furze, Leon. ﬁ Teaching A I Ethic s.ﬂ 
Leon  Furze:  Reading,  Writing,  Digital
, 26 Jan. 2023, 
leonfurze
 
.com/2023/01/26/tea ching-ai-ethic s/
. 
Goodlad, Lauren M. E., and S amuel Baker. ﬁNow the Humanities Can Disrupt AI.ﬂ 
Public  Books
, 20 Feb. 2023,  
www.publicbooks.org/now-the-humanities-can-disrupt-ai/
.
Marcus, Gary. ﬁA I Platforms like 
ChatGPT
 Are Easy to Use but Also Potentially Dangerous.ﬂ 
Scienti˚c 
American
, 1 9 Dec. 2022, 
www.scie nti˙ca m e rican.com/a rt icle/ai-platforms-like-chatgpt-a re-easy-to
 
-use-but-al so-potentially-dangerous/
. 
Miller, Matt. ﬁUsing GPT on Library Collections: Use Cases for Applying GP T3/3 .5 /4 on a Full Text Collection.ﬂ  
Matt  Mil ler
, 30 Mar. 2023, 
thisismattmille r.com/post/using-gpt-on-libra ry-collections/
.
Mills, Anna, curator. ﬁA I Text Generators and Teaching Writing: Starting Points for Inquiry.ﬂ 
WAC  
Clearinghouse
, 14 Feb. 2023, 
wac.colostate.edu/repository/collections/ai -text-generators-and
 
-teaching-writing-st a rting-points-for- inquiry/
. 
Mills, Anna, and Lauren Goodlad. ﬁAdapting College Writing for the Age of Large Language Models such as  
ChatGPT
: Some Next Steps for Educators.ﬂ 
Critica l  A I
, 17 Jan. 2023, 
crit icalai.org/2023 /01/17/critical-ai
 
-adapting-college-writing-for-the-age-of-large-language-models-such-as-chatgpt-some-next-steps
 
-for-educators/
. 


  
13
N icholas, Gabriel, and Aliya Bhatia. ﬁLost in Translat ion: Large Language Models in Non-English Content  
Analysis.ﬂ 
Center for Democracy and Technology
, 23 May 2023, 
cdt.org/insights/lost- in-tra nslation
 
-large-language-models- in-non-english-content-analysis/
. 
Okerlund, Johanna, et al. ﬁWhat™s in the Chatterbox? Large Language M odel s, Why They Matter, and What  
We  Should  Do  About  Them.ﬂ  
Gerald  R.  Ford  School  of  Public  Policy
, Regents of the U niversity of  
Michigan,  Apr.  2022,  
stpp.fordschool.umich.edu/research/research-report/whats- in-t he-chatterbox
.
Perrigo, Billy. ﬁ150 African Workers for 
ChatGPT
, 
TikTok
 and 
Facebook
 Vote to U nionize at Landmark Nairobi  
Meeting .ﬂ 
Time
, 1 May 2023, 
tim e.com/6275995/chatgpt-facebook-african-workers-union/.
Poole, Frederick. ﬁUsing 
ChatGPT
 to Design Language Material and Exercises.ﬂ 
FLTM AG
, 13 Dec. 2022,  
tmag .com/chatgpt-design-material- exercises/
.
ﬁQuick St art Guide to A I and Writing.ﬂ 
MLA-CCCC Joint Task Force on Writing and AI: Addressing AI Issues in  
Relation  to  Student  Writing  and  Scholarship
, MLA-CCCC J oint Task Force on Writing and A I , 21 Feb.  
2023,  
aiandwriting .hcommons.org/resources/
.
Rudolph, Jürgen, et al. ﬁ
ChatGPT
: Bullshit Spewer or the End of Traditional Assessments in Higher  
Education?ﬂ 
Journal  of  Applied  Learning  and Teaching
, vol. 6, no. 1, 2023, pp. 3 42Œ 63 .  
ﬁRunning List of Articles (2023 ).ﬂ 
Google Docs
, 18 Jan. 2023, 
doc s.google.com/document/d/1qK7pcBM8V3xB
H0EOZTJZ3XnnTzbouKIEY_ 884BGaJ1M/edit
.
Sabzalieva,  Emma,  and  Arianna  Valentini.  ﬁ
ChatGPT
 and Arti˙cial Intelligence in Higher Education: Quick  
Start Guide.ﬂ United Nations Educational, Scienti˙c and Cultural Organization / UNESCO International  
Institute for Higher Education in Latin America, 2023 . 
UNESCO  Digital  Library
, 
unesdoc.unesco.org/
ark:/48223/pf0 0 0 03 85146. locale=en
.


  
14
Appendix: Responses to the CCCC-ML A Joint Task Force Questionnaire
In March and April 2023, the MLA and CCCC collaborated on disseminating a feedback form to learn more  
from stakeholders about their perceptions of t he signi˙cance of large language models for their classrooms,  
programs, and campuses. In a subsequent working paper, we will provide an in-depth report on the results  
of the questionnaire. For the purposes of this working paper, two questions are relevant: What concerns,  
if any, do you have about use of 
ChatGPT
 and other A I text generation technologies in teaching, and  
what opportunities, if any, do you see in the use of 
ChatGPT
 and other A I text generation technologies in  
tea ching?  
Of the 456 respondents to the question on concerns (˙ve being most concerned and one being least  
concerned) the response level on a scale of ˙ve was 3 .82. The two most common categories of concerns  
included concerns about plagiarism and integrity, and the inability of instructors to be able to detect A I. The  
second signi˙cant category of concern focused on respondents expressing worries that students would use  
A I instead of learning to write, practice important writing or critical thinking skills, learn a language, or to learn  
in  general.  
Of the 412 respondents who provided a response to the question about opportunities, the average was  
3 .24. The most common opportunities ident i˙ed by A I and writing focused on the technology being helpful  
to students™ writing processes at multiple stages. The next most commonly identi˙ed opportunity focused on  
the possibility t hat A I tools can help students think about aspects of A I writing and its limitations and to learn  
how to improve on it (e.g ., creating example papers or text for students to evaluate or revise). Perhaps mos t  
telling was that a large number of respondents to this question were unsure of possible opportunities or did  
not  see  any opportunities.  
However, graphing the responses show that the level of concern in terms of the data dis tribution is  
signi˙cantly higher (being skewed toward greater concern) than the level of opportunity, which was more  
evenly  distributed  across  responses (
see ˙gs. 1Œ2
).  


  
15
Figure  1:
 Distrib ution  of  responses  to  qu estion  7.  
Figure  2:
 Response  distrib ution  to  qu estion  9  
 
reg ardin g  opportunities .